{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9942599",
   "metadata": {},
   "source": [
    "# Google Cloud Platform\n",
    "\n",
    "## Índice\n",
    "\n",
    " - Crear una cuenta gratuita GCP, de 90 días y 300\\$\n",
    " - Crear un bucket en Google Cloud Storage (GCS) y alamcenar ahí toda nuestra información (Códigos, datos, ficheros, documentación...)\n",
    " - Crear repositorios de datos en BigQuery y hacer consultas y vistas en BigQuerySQL\n",
    " - Crear instancias VertexAI Workbench para abrir notebooks de python, donde también hacer uso de los datos, sean de GCS o BigQuery\n",
    " - Conectar workbench con GitHub\n",
    " - Visualizacion con Looker\n",
    " - Programar acciones con Scheduler o Airflow, Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57024329",
   "metadata": {},
   "source": [
    "## Crear cuenta gratuita\n",
    "\n",
    " - Entra en [GCP](https://cloud.google.com/free?hl=es_419) o teclea en internet GCP Free trier\n",
    " - Sigue los pasos para crear la cuenta. Requisitos: Tener cuenta gmail y una tarjeta de crédito, No se te cobrará nada inicialmente, solo en caso de exceder los 90 días o los 300$ de prueba. \n",
    "\n",
    "Automáticamente se te habrá creado un proyecto: \"My First Proyect\". Puedes crear más si lo necesitas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a01cc",
   "metadata": {},
   "source": [
    "## Google Cloud Storage\n",
    "\n",
    "Crear in bucket en GCS:\n",
    " - Dentro de GCP, en la barra de búsqueda, escribe \"Cloud Storage\"\n",
    " - Después Create a Bucket\n",
    " - Dale un nombre\n",
    " - Prueba a crear una carpeta y a subir un fichero csv o cualquier documento para comprobar que funciona bien\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0ad8e",
   "metadata": {},
   "source": [
    "## BigQuery\n",
    "\n",
    " - Busca BigQuery en la barra de búsqueda\n",
    " - En el menú de la izquierda tienes un explorador con todos tus objetos BigQuery\n",
    " - Niveles jerárquicos: \n",
    "   - Repositories, Query, Notebooks, Data Canvases, Data Preparation, Pipelines, External Connections, Datasets\n",
    "   - **Datasets** contiene los datos, sean tablas o vistas (Proyect_id.dataset.tabla)\n",
    "   - **Queries** es donde se guardan los códigos con nuestras consultas a los datos (de Datasets)\n",
    "   \n",
    " \n",
    " ## Cargar datos en BigQuery\n",
    " \n",
    " \n",
    " - A través de **interfaz**\n",
    "   - En la parte alta del explorador tenemos el botón Add Data, que nos lleva a un menú en el que tendremos que elegir la fuente de datos (Local, GCS, Google Sheets...)\n",
    "   - Si no tenemos ningún dataset creado, o queremos crear otro, en este menú podemos hacerlo. Nos pedirá indicar en qué dataset guardar la nueva tabla.\n",
    "   - En la parte baja de este menú tenemos Advanced Options, donde podemos indicar el delimitador de las columnas de nuestros datos\n",
    "   - Al clicar en Create, se nos creará una nueva tabla en el dataset, de nuevo en el menú Explorador de la izquierda.\n",
    " \n",
    " \n",
    " - Con **comando SQL**:\n",
    "   - Comandos SQL (`LOAD DATA`)\n",
    "\n",
    "```sql\n",
    "LOAD DATA INTO `proyecto.dataset.tabla`\n",
    "FROM FILES (\n",
    "  format = 'CSV',\n",
    "  uris = ['gs://bucket/archivo.csv']\n",
    ")\n",
    "\n",
    "```   \n",
    "\n",
    "   - Desde **Vertex AI Workbench** (Python)\n",
    "   \n",
    "   ```python\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Carga desde DataFrame de Pandas\n",
    "    df.to_gbq(\n",
    "      destination_table='dataset.tabla',\n",
    "      project_id='proyecto',\n",
    "      if_exists='append'  # o 'replace'\n",
    "    )\n",
    "\n",
    "    # Carga desde GCS\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "      source_format=bigquery.SourceFormat.CSV,\n",
    "      skip_leading_rows=1\n",
    "    )\n",
    "\n",
    "    load_job = client.load_table_from_uri(\n",
    "      \"gs://bucket/archivo.csv\",\n",
    "      \"dataset.tabla\",\n",
    "      job_config=job_config\n",
    "    )\n",
    "```\n",
    "\n",
    " \n",
    "## Guardar Query\n",
    "\n",
    " - Haz una query de prueba para comprobar que tus datos se cargaron correctamente\n",
    " \n",
    " ```sql\n",
    " select * from `project_id.dataset.table_name`\n",
    " ```\n",
    " \n",
    " - Clica en el botón Save Query e indica un nombre para ella. Verás que se guarda dentro del proyecto en el **nivel jerárquico Queries**\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0419ed",
   "metadata": {},
   "source": [
    "## Crear instancias Vertex AI Workbench\n",
    "\n",
    " - En la barra de búsquedas: VertexAI Workbench\n",
    " - Create New\n",
    "  - Dale un nombre, \n",
    "  - Selecciona: \n",
    "    - una región y una zona\n",
    "    - un environment y Operating system\n",
    "    - Una máquina, dependiendo de la potencia tendrá un costo u otro\n",
    " - Una vez creada iníciala clicando en Start, y podrás clicar en Open JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d4a36",
   "metadata": {},
   "source": [
    "## Instalar Python\n",
    "\n",
    "Normalmente debería venir con python ya instalado e incluso con algunos entornos ya preconfigurados e instalados, pero si no:\n",
    "\n",
    "Instalar python. Los códigos que se requiere ejecutar para instalar las dependiencias pueden ser ejecutados en:\n",
    "\n",
    " - En el notebook abierto a partir de la instancia VertexAI Workbench, en el menú izquierdo en el botón '+' y abre una consola\n",
    " - Abrir una CLoud Shell Terminal en la página principal de GCP\n",
    "\n",
    " - Actualiza la lista de paquetes\n",
    "```bash\n",
    "sudo apt update\n",
    "```\n",
    " - Actualiza los paquetes instalados\n",
    "```bash\n",
    "sudo apt upgrade\n",
    "```\n",
    " - Instala Python\n",
    "```bash\n",
    "sudo apt install -y python3 python3-pip python3-venv\n",
    "```\n",
    " - Crea un entorno virtual\n",
    "```bash\n",
    "python3 -m venv env_consorci\n",
    "```\n",
    " - Activa el entorno virtual\n",
    "```bash\n",
    "source env_consorci/bin/activate\n",
    "```\n",
    "\n",
    "### Instalar librerías desde requirements.txt\n",
    "\n",
    "\n",
    " - Guarda tu fichero requierments.txt en GCS\n",
    "   - Este fichero contiene los nombres de las librerías que quieres instalar (pandas, matplotlib, scikitlearn...)\n",
    "   \n",
    " - Descarga el fichero a tu instancia\n",
    " \n",
    "```bash\n",
    "gsutil cp gs://bucket-consorci/requirements.txt .\n",
    "```\n",
    "\n",
    " - Instalar las dependencias\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f10a1",
   "metadata": {},
   "source": [
    "## Clonar Github en nuestro entorno\n",
    "\n",
    " - Instalar GitHub\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install -y git\n",
    "```\n",
    "\n",
    " - Abre una terminal dentro del JupyterLab y ejecuta\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/bvzq/DS_Consorci_2025\n",
    "```\n",
    "\n",
    "El repositorio se descargará en el directorio actual de tu instancia (/home/jupyter/ por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84dbfe",
   "metadata": {},
   "source": [
    "## Looker Studio\n",
    "\n",
    "Busca en la barra de búsquedas \"Looker Studio\" o clica en https://lookerstudio.google.com\n",
    "\n",
    " - New Report\n",
    " - Add data > BigQuery > project > dataset > table\n",
    "\n",
    "A partir de aquí, podemos añadir gráficos (Add a Chart), filtros, poner titulos, cambiar la configuraciónde las visualizaciones... Como en PowerBI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4641dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c5436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138f254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0904ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15aa1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e497c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e4781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
