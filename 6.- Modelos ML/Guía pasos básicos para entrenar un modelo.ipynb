{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909d314e",
   "metadata": {},
   "source": [
    "## Pasos básicos para entrenar un modelo\n",
    "\n",
    " - Importar datos y librerías\n",
    " \n",
    " - División conjunto de datos en train/test. \n",
    "   - Todos los pasos de a continuación los tratamos con los datos de entrenamiento. \n",
    "   - Los datos de test los guardamos y no los utilizamos hasta el final del proceso, en donde, si es necesario, se aplicarán las trasformaciones pertinentes basándose en los criterios obtenidos a partir del conjunto de entrenamiento. Esto es, por ejemplo, que si sustituimos los Nan en una variable por su media, en el conjunto de test usaremos la media con la que hemos sustituido en el conjunto de entrenamiento. No volveremos a calcular la media del conjunto de test. Si categorizamos una variable continua en el conjunto de entrenamiento usando unos puntos de corte, éstos los tendremos también en cuenta para categorizar esa variable en el conjunto de test. Y así con todas las casuísticas que pudieran surgir. Principalmente con la estandarización.\n",
    " \n",
    " - Análisis Descriptivo:\n",
    "   - Encontrar y gestionar valores nulos, perdidos, extremos\n",
    "   - Analizar asociaciones entre las variables independientes entre sí y con la variable objetivo. Para ello, hay que servirse de tablas de doble entrada o tablas de contingencia, groupby y pivot table con conteos y métricas (media, std, mediana) y de visualizaciones gráficas (historgramas, gráficos de barras, tarta, mapas, lineales...)\n",
    "   - Encontrar correlaciones y colinealidad entre las variables independientes entre sí, usando la correlación de pearson, VIF o la V de Cramer.\n",
    "   - Determinar si la variable dependiente es continua o discreta. \n",
    "     - Si es discreta, cuántas categorías? están balanceadas?\n",
    "     - Si es continua, sigue una distribución normal? Están los datos centrados en algún punto o tiene muchos valores extremos hacia ambos lados? Si así fuera, podríamos eliminar esos datos, ahora bien, el modelo final podría verse limitado y no saber predecir instancias de ese tipo. También puede dividirse el data set para hacer dos modelos independientes. Esta división deberá depender de una variable independiente, no de la variable objetivo. Es decir, por ejemplo, dependerá del tamaño de las viviendas, no del precio.\n",
    "     \n",
    "- Ingeniería de variables: A partir del análisis descriptivo previo y las posibles asociaciones encontradas, crear nuevas variables que optmicen la predicción, la interpretabilidad y la eficiencia del proceso de entrenamiento del modelo.\n",
    "    - Recategoriza variables categóricas uniendo categorías que tengan un comportamiento similar entre ellas, o que no tengan un peso representativo, o que por conocimiento del negocio puedan significar la misma cosa o puedan ser interpretadas como tal.\n",
    "    - Considera categorizar las variables continuas, ya sea por algún criterio de tu negocio o usando indicadores estadísticos especializados, como el WOE\n",
    "    - También puedes crear variables categóricas combinaciones unas de otras, como estado civil y tipo de vivienda (comprada, hipoteca, heredada, alquilada...)\n",
    "\n",
    "- Estandarización y Dummy\n",
    "    - Estandariza las variables numéricas si vas a entrenar un modelo que utilice coeficientes o pesos, por ejemplo regresión logística, regresión lineal o MLP (Redes neuronales)\n",
    "    - Codifica tus variables categóricas a números (0, 1, 2...) si vas a entrenar modelos tipo árbol (Random Forest, AdaBoost, XGBoost...)\n",
    "    - Dicotomiza tus variables categóricas si vas a entrenar a través de Regresión lineal o Regresión logística\n",
    "\n",
    "- En el caso de los modelos con variable objetivo categórica:\n",
    "    - Asegúrate de que todas las clases tienen un peso similar. Para ello, haz oversampling, undersampling o class_weight ='balanced' (Entendiendo qué ocurre cuando aplicas una técnica u otra).\n",
    "\n",
    "- Selección de modelo, hiperparámetros y variables a introducir\n",
    "    - Dependiendo de tu problema a resolver habrá unos modelos que te sean más apropiados utlizar para predecir tu variable objetivo. Piensa en cuáles pueden ser.\n",
    "    - Apóyate usando técnicas como la cross-validation y Grid Search, para que la selección del modelo, los hiperparámetros y las variables sea más pertinente. \n",
    "      - Analiza la media y la varianza de la performance de todas las iteraciones de la CV para elegir entre un modelo y otro\n",
    "      - Grid Search está más pensado para encontrar los hiperparámetros. También nos devuelve la media y varianza de las performances y deberá ser tenido en cuenta también para esta selección. \n",
    "        - Los hiperparámetros más relevantes a optimizar son: Para las regresiones, Regularización (penalty), optimizador (solver), Learning rate de la regularización (C). Para los Random Forest, número de árboles (n_estimators), profundidad de los árboles (max_depth), criterio de selección (criterion)\n",
    "      - Para encontrar las variables que mejor funcionan para predecir tu variable objetivo usa SequentialFeatureSelector o la función Selección diseñada manualmente. En los algoritmos tipo árbol, la selección de variables no es tan imprescindible, pues el propio algoritmo ejerce ese papel.\n",
    "\n",
    "- Una vez encontradas las características mejores de tu modelo, entrenamos de manera definitiva el modelo.\n",
    "\n",
    "- Evaluación del modelo:\n",
    "  - Recuperamos en este punto el conjunto de test separado en el primer paso.\n",
    "  - En caso de haber creado nuevas variables o modificado las originales, realiza esas transformaciones en el conjunto de test, usando los criterios del conjunto de entrenamiento.\n",
    "  - Introduce el conjunto de validación en el modelo y obtendrás una predicción.\n",
    "  - Compara la variable objetivo y la predicción para validar la calidad de dicha predicción.\n",
    "    - Si la variable objetivo es continua usa métricas como MSE, RMSE, MAE y MAPE. Si además usaste regresión lineal, analiza el $R^2$ como indicador de bondad de ajuste\n",
    "    - Si la variable objetivo es categórica, mide la bondad de ajuste usando métricas como Accuracy, Precisión, Recall (Potencia), F-Score, AUC\n",
    "  - Si el modelo utilizado es una Regresión Logística, analiza el punto de corte y de nuevo esas métricas para encontrar el que más se ajusta a tu modelo de negocio.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb090319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
